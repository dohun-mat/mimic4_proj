{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dhk/physionet.org/files/mimiciv/2.2/hosp\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "import pandas as pd\n",
    "%cd /data/dhk/physionet.org/files/mimiciv/2.2/hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dh = cudf.read_csv(\"process_dohun.csv\")\n",
    "\n",
    "df_dh = df_dh.drop('subject_id', axis=1)\n",
    "df_dh = df_dh.drop('hadm_id', axis=1)\n",
    "df_dh\n",
    "\n",
    "y = df_dh['hospital_expire_flag'] \n",
    "X = df_dh.drop('hospital_expire_flag', axis=1) # 'label' 열을 제외한 나머지 열을 X로 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from cuml.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.099931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=20; total time=36.2min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.019612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=30; total time=382.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.684525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=20; total time=24.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.087796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=40; total time=251.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.952359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=40; total time=249.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.992393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=30; total time=182.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.323251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=30; total time=39.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.753851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=30; total time=384.6min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.756153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=30; total time=36.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.224422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=40; total time=47.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.857359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=30; total time=178.1min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.562833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=20; total time=130.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.642119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=30; total time=39.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.239374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=20; total time=134.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.985408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=30; total time=379.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.138490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=30; total time=195.2min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.874945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=20; total time=124.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.553709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=30; total time=367.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.047987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=40; total time=52.1min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.827469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=20; total time=26.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.990568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=20; total time=25.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.814906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=20; total time=26.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.098268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=30; total time=39.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.651181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=40; total time=52.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.890511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=30; total time=196.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.830295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=30; total time=36.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.441994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=40; total time=47.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.191567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=30; total time=188.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.574047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=40; total time=254.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.264535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=40; total time=257.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.956019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=30; total time=187.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.571602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=40; total time=51.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.155946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=40; total time=668.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.973074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=20; total time=26.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.651503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=30; total time=378.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.497410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=20; total time=22.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.831363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=30; total time=36.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.863500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=40; total time=48.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.242303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=40; total time=225.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.741380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=40; total time=260.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.782370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=20; total time=252.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.479070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=40; total time=226.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.417300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=20; total time=254.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.036126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=40; total time=254.8min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.668363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=40; total time=234.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.752735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=40; total time=260.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.827856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=20; total time=253.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.816475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=40; total time=236.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.165138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=30; total time=266.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.820876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=20; total time=256.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.836683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=40; total time=234.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.664444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=20; total time=26.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.789857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=20; total time=256.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.114128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=20; total time=256.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.833412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=20; total time=217.2min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.464019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=40; total time=51.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.685423 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=40; total time=486.8min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.077415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=20; total time=229.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.473642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=30; total time=39.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.911686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=40; total time=511.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.662338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=20; total time=222.5min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.599032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=30; total time=194.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.775122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=20; total time=134.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.776595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=40; total time=445.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.994560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=20; total time=131.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.868215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=40; total time=53.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.701341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=20; total time=135.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.131551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=40; total time=458.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.576003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=40; total time=52.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.126309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=20; total time=26.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.711431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=20; total time=26.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.647663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=30; total time=39.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.860618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=40; total time=51.2min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.011557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=30; total time=187.9min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.761594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=40; total time=423.4min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.952720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=40; total time=51.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.322551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=40; total time=502.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.467963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=20; total time=259.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.655862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=30; total time=195.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.862435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=30; total time=200.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.752961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=40; total time=417.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.236411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=30; total time=195.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.936741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=30; total time=198.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.872504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=40; total time=425.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.168780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=30; total time=39.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.556450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=40; total time=515.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.448182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=20; total time=265.8min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.479482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=30; total time=38.9min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.288135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=30; total time=373.9min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.411162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=20; total time=23.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.404432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=30; total time=36.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.703465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=20; total time=119.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.043389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=30; total time=249.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.388359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=20; total time=128.8min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.965757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=30; total time=39.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.145926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=40; total time=50.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.206299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=30; total time=186.1min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.667275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=20; total time=24.2min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.636689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=30; total time=36.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.373358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=20; total time=120.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.599294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=30; total time=256.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.542835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=30; total time=38.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.200270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=30; total time=375.9min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.604422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=20; total time=23.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.887635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=40; total time=48.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.559893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=20; total time=118.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.973132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=30; total time=241.8min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.064080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=20; total time=130.6min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.711622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=30; total time=38.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.882820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=100, num_leaves=40; total time=53.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.294549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=40; total time=259.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.863458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=20; total time=126.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.694429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=30; total time=242.4min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.336804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=40; total time=257.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.952952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=20; total time=354.7min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.746666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=30; total time=240.1min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.807209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=100, num_leaves=40; total time=48.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.649670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=20; total time=126.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.816260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=40; total time=269.5min\n",
      "[LightGBM] [Info] Number of positive: 4139237, number of negative: 4140999\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.510699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 713\n",
      "[LightGBM] [Info] Number of data points in the train set: 8280236, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.067520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=20; total time=26.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.240518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=20; total time=261.3min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.847153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=30; total time=361.9min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.789972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=40; total time=241.5min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.690105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624188, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END .learning_rate=0.1, n_estimators=100, num_leaves=20; total time=26.2min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.090395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=20; total time=264.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.636690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=30; total time=381.2min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.864860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=40; total time=221.0min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.363187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.1, n_estimators=1000, num_leaves=20; total time=253.3min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.635210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=40; total time=245.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.863460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.001, n_estimators=500, num_leaves=30; total time=181.0min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.857341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=40; total time=216.1min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.384924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 711\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.1, n_estimators=500, num_leaves=20; total time=178.7min\n",
      "[LightGBM] [Info] Number of positive: 3311389, number of negative: 3312800\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.596621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499893 -> initscore=-0.000426\n",
      "[LightGBM] [Info] Start training from score -0.000426\n",
      "[CV] END learning_rate=0.01, n_estimators=500, num_leaves=20; total time=125.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.824906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.01, n_estimators=1000, num_leaves=30; total time=360.8min\n",
      "[LightGBM] [Info] Number of positive: 3311390, number of negative: 3312799\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.116073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 717\n",
      "[LightGBM] [Info] Number of data points in the train set: 6624189, number of used features: 9\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499894 -> initscore=-0.000425\n",
      "[LightGBM] [Info] Start training from score -0.000425\n",
      "[CV] END learning_rate=0.001, n_estimators=1000, num_leaves=40; total time=228.4min\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mget(), y_train\u001b[38;5;241m.\u001b[39mget())\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 최적 매개변수 출력\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/model_selection/_search.py:547\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    the best found parameters.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    546\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/lightgbm/sklearn.py:1223\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1221\u001b[0m ):\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mor\u001b[39;00m raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib:\n\u001b[1;32m   1234\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/lightgbm/sklearn.py:1253\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1243\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1251\u001b[0m ):\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1253\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[1;32m   1264\u001b[0m         _log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1265\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/lightgbm/sklearn.py:934\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m--> 934\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMCheckArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m!=\u001b[39m n_features:\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/utils/validation.py:1007\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1011\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/utils/_array_api.py:746\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    744\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1475\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__array__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly."
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=42)\n",
    "\n",
    "X_train = X_train.to_cupy()\n",
    "X_test = X_test.to_cupy()\n",
    "y_train = y_train.to_cupy()\n",
    "y_test = y_test.to_cupy()\n",
    "\n",
    "# X_train = X_train.to_numpy()\n",
    "# X_test = X_test.to_numpy()\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "\n",
    " # 매개변수 그리드 정의\n",
    "param = {\n",
    "  'num_leaves': [20, 30, 40],\n",
    "  'learning_rate': [0.1, 0.01, 0.001],\n",
    "  'n_estimators': [100, 500, 1000],\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(model, param_grid=param, cv=5, refit=True, n_jobs=-1, return_train_score=True, verbose=2, error_score='raise')\n",
    "# 훈련 데이터로 모델 학습 및 최적 매개변수 탐색\n",
    "best_model = grid_search.fit(X_train.get(), y_train.get())\n",
    "# 최적 매개변수 출력\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9559462070465088\n",
      "Accuracy: 0.9559462044578418\n",
      "F1 Score: 0.9568415801942824\n"
     ]
    }
   ],
   "source": [
    "import cuml\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cu_score = cuml.metrics.accuracy_score( y_test, y_pred )\n",
    "print(cu_score)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test.get(), y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test.get(), y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# randomForest_y_pred를 Pandas DataFrame으로 변환\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "y_pred_df.to_csv('lightgbm_y_pred.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mach",
   "language": "python",
   "name": "mach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
