{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dhk/physionet.org/files/mimiciv/2.2/hosp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "%cd /data/dhk/physionet.org/files/mimiciv/2.2/hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>medication</th>\n",
       "      <th>frequency</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.928571</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>806</td>\n",
       "      <td>16</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>91</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350291</th>\n",
       "      <td>-0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>121</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350292</th>\n",
       "      <td>-0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>121</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350293</th>\n",
       "      <td>-0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>121</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350294</th>\n",
       "      <td>-0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>121</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10350295</th>\n",
       "      <td>-0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1552</td>\n",
       "      <td>121</td>\n",
       "      <td>1659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10350296 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          admit_age  gender  insurance  language  marital_status  race  \\\n",
       "0         -0.928571       1          2         1               1    28   \n",
       "1         -0.071429       0          2         1               1    28   \n",
       "2         -2.071429       0          2         1               1    28   \n",
       "3         -0.571429       1          2         1               2    28   \n",
       "4         -1.000000       1          2         1               0    28   \n",
       "...             ...     ...        ...       ...             ...   ...   \n",
       "10350291  -0.785714       1          2         1               2    28   \n",
       "10350292  -0.785714       1          2         1               2    28   \n",
       "10350293  -0.785714       1          2         1               2    28   \n",
       "10350294  -0.785714       1          2         1               2    28   \n",
       "10350295  -0.785714       1          2         1               2    28   \n",
       "\n",
       "          hospital_expire_flag  medication  frequency  drug  \n",
       "0                            0          50         95    34  \n",
       "1                            0         806         16   860  \n",
       "2                            0          50         95    72  \n",
       "3                            0          15         16  1786  \n",
       "4                            0         458         91   503  \n",
       "...                        ...         ...        ...   ...  \n",
       "10350291                     1        1552        121  1659  \n",
       "10350292                     1        1552        121  1659  \n",
       "10350293                     1        1552        121  1659  \n",
       "10350294                     1        1552        121  1659  \n",
       "10350295                     1        1552        121  1659  \n",
       "\n",
       "[10350296 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proodh = pd.read_csv(\"process_dohun.csv\")\n",
    "df_dh = cudf.read_csv(\"process_dohun.csv\")\n",
    "\n",
    "df_dh = df_dh.drop('subject_id', axis=1)\n",
    "df_dh = df_dh.drop('hadm_id', axis=1)\n",
    "df_dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=219.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=804.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=233.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=215.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=212.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=189.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=159.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=72.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=41.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=129.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=123.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=24.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=25.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=863.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=142.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=24.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=245.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=115.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=218.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=690.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=129.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=125.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=124.0min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=124.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=863.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=151.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=236.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=24.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=25.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=123.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=216.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=688.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=29.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=242.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=244.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=867.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=260.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=123.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=25.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=123.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=1010.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=23.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=24.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=245.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=123.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=865.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=267.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=25.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=244.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=218.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=688.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=124.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=122.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=246.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=1015.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=23.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=24.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=24.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=25.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=25.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=246.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=216.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=688.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=131.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=124.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=25.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=97.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=215.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=225.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=198.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=151.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=185.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=237.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=239.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=1016.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=116.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=124.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.0min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=91.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=1008.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=236.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=220.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=863.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=140.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=235.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=221.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=1019.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=238.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.0min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=108.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=215.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=212.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=636.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=24.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=24.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=124.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=215.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=219.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=806.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=237.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=224.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=1016.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=117.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=122.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=122.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=114.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=1015.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=116.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=123.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=114.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=219.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=804.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=233.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=235.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=216.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=686.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=28.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=244.9min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=123.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=196.3min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=1015.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=24.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=124.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=123.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=25.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=194.4min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=223.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=803.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=24.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=247.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=202.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=867.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=39.2min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=100; total time=26.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=124.0min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=248.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=200.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=863.5min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=147.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=100; total time=23.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=100; total time=25.0min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=250.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=204.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=865.7min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=265.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=248.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=152.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=500; total time=863.8min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=266.8min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=248.6min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=151.1min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=1016.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=120.1min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=250.5min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=158.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhkim/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=500; total time=863.9min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.1, n_estimators=1000; total time=266.7min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=247.4min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=166.0min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=1016.6min\n",
      "[CV] END algorithm=SAMME, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=500; total time=118.3min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.01, n_estimators=1000; total time=247.2min\n",
      "[CV] END algorithm=SAMME.R, estimator=DecisionTreeClassifier(max_depth=3), learning_rate=0.001, n_estimators=1000; total time=170.2min\n",
      "최적 매개변수: {'algorithm': 'SAMME.R', 'estimator': DecisionTreeClassifier(max_depth=3), 'learning_rate': 0.1, 'n_estimators': 1000}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# 최적 매개변수로 모델 재학습\u001b[39;00m\n\u001b[1;32m     54\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m---> 55\u001b[0m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(test)\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:133\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a boosted classifier/regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m--> 133\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[1;32m    144\u001b[0m     sample_weight, X, np\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m sample_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/utils/validation.py:1273\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[0;32m-> 1273\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1291\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/utils/validation.py:1007\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1007\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1011\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mach/lib/python3.9/site-packages/sklearn/utils/_array_api.py:746\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    744\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32mcupy/_core/core.pyx:1475\u001b[0m, in \u001b[0;36mcupy._core.core._ndarray_base.__array__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from cuml.model_selection import train_test_split  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = AdaBoostClassifier()\n",
    "\n",
    "y = df_dh['hospital_expire_flag'] \n",
    "X = df_dh.drop('hospital_expire_flag', axis=1) # 'label' 열을 제외한 나머지 열을 X로 사용\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8,random_state=42)\n",
    "\n",
    "X_train = X_train.to_cupy()\n",
    "X_test = X_test.to_cupy()\n",
    "y_train = y_train.to_cupy()\n",
    "y_test = y_test.to_cupy()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# X_train = X_train.to_numpy()\n",
    "# X_test = X_test.to_numpy()\n",
    "# y_train = y_train.to_numpy()\n",
    "# y_test = y_test.to_numpy()\n",
    "\n",
    "# 매개변수 그리드 정의\n",
    "param = {\n",
    "  'learning_rate': [0.1, 0.01, 0.001],\n",
    "  'n_estimators': [100, 500, 1000],\n",
    "  'learning_rate': [0.1, 0.01, 0.001],\n",
    "  'n_estimators': [100, 500, 1000],\n",
    "  'estimator': [DecisionTreeClassifier(max_depth=3), DecisionTreeClassifier(max_depth=3)],\n",
    "  'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "\n",
    "# AdaBoostClassifier 생성\n",
    "ada_boost = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "# GridSearchCV 객체 생성\n",
    "grid_search = GridSearchCV(ada_boost, param_grid=param, cv=5, refit=True, n_jobs=-1, return_train_score=True, verbose=2, error_score='raise')\n",
    "\n",
    "# 훈련 데이터로 모델 학습 및 최적 매개변수 탐색\n",
    "grid_search.fit(X_train.get(), y_train.get())\n",
    "\n",
    "# 최적 매개변수 출력\n",
    "print(\"최적 매개변수:\", grid_search.best_params_)\n",
    "# 최적 매개변수로 모델 재학습\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8790247440338135\n",
      "Accuracy: 0.8790247625672686\n",
      "F1 Score: 0.8838944365060305\n"
     ]
    }
   ],
   "source": [
    "import cuml\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cu_score = cuml.metrics.accuracy_score(y_test, y_pred )\n",
    "print(cu_score)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test.get(), y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1 = f1_score(y_test.get(), y_pred)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# randomForest_y_pred를 Pandas DataFrame으로 변환\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "y_pred_df.to_csv('adaboost_pred.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mach",
   "language": "python",
   "name": "mach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
